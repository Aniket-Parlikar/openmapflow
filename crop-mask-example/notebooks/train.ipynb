{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBYSuraxoKJy"
   },
   "source": [
    "# Model training üèã\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasaharvest/openmapflow/blob/main/crop-mask-example/notebooks/train.ipynb)\n",
    "\n",
    "**Description:** Stand alone notebook for training crop-mask models. \n",
    "\n",
    "<img src=\"https://storage.googleapis.com/harvest-public-assets/openmapflow/train_model.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdI-wLrbxHZn"
   },
   "source": [
    "# 1. Setup\n",
    "\n",
    "If you don't already have one, obtain a Github Personal Access Token using the steps [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token). Save this token somewhere private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3otirx9-y6M"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    \n",
    "if IN_COLAB:\n",
    "    email = input(\"Github email: \")\n",
    "    username = input(\"Github username: \")\n",
    "\n",
    "    !git config --global user.email $username\n",
    "    !git config --global user.name $email\n",
    "\n",
    "    from getpass import getpass\n",
    "    token = getpass('Github Personal Access Token:')\n",
    "\n",
    "    # TODO: Generate below two lines from config\n",
    "    !git clone https://$username:$token@github.com/nasaharvest/openmapflow.git\n",
    "    !cd openmapflow && pip install -r requirements.txt -q\n",
    "    %cd openmapflow/crop-mask-example\n",
    "else:\n",
    "    print(\"Running notebook outside Google Colab. Assuming in local repository.\")\n",
    "    !cd ../.. && pip install -r requirements.txt -q\n",
    "    !pip install earthengine-api google-auth -q\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzZn9b3f2ySY"
   },
   "outputs": [],
   "source": [
    "!pip install torch wandb tsai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWoGz94avN0w"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import wandb\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from openmapflow.config import RELATIVE_PATHS, FULL_PATHS, PROJECT_ROOT\n",
    "from openmapflow.pytorch_dataset import PyTorchDataset\n",
    "from openmapflow.config import SUBSET\n",
    "\n",
    "from datasets import datasets\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning) # TorchScript throws excessive warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEusgSrCqxaz"
   },
   "source": [
    "# 2. Download latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls-7sN9Hoew6"
   },
   "outputs": [],
   "source": [
    "for path_key in tqdm([\"models\", \"processed\", \"compressed_features\"]):\n",
    "    !dvc pull {RELATIVE_PATHS[path_key]} -q\n",
    "\n",
    "!tar -xzf {RELATIVE_PATHS[\"compressed_features\"]} -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeANCDe2uJcX"
   },
   "outputs": [],
   "source": [
    "# Currently available models\n",
    "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAD4tO5k7nO5"
   },
   "outputs": [],
   "source": [
    "# Available datasets for training and evaluation\n",
    "!cat data/datasets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gietI36Bykse"
   },
   "source": [
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P13Z7qUQfMJ"
   },
   "source": [
    "### 3.1 Import model\n",
    "Any PyTorch based model that can take sequence data as input will work here.\n",
    "Example uses a PyTorch model from [tsai](https://github.com/timeseriesAI/tsai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEUjElwSELhF"
   },
   "outputs": [],
   "source": [
    "from tsai.models.TransformerModel import TransformerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAYc2qnpQXu1"
   },
   "source": [
    "### 3.2 Setup training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBX3COiquUPN"
   },
   "outputs": [],
   "source": [
    "# ------------ Dataloaders -------------------------------------\n",
    "batch_size = 64\n",
    "df = datasets[0].load_labels()\n",
    "split_dfs = {\n",
    "    \"training\": df[df[SUBSET] == \"training\"],\n",
    "    \"validation\": df[df[SUBSET] == \"validation\"],\n",
    "    \"test\": df[df[SUBSET] == \"testing\"]\n",
    "}\n",
    "data = {split: PyTorchDataset(df=df) for split, df in split_dfs.items()}\n",
    "data_loaders = {}\n",
    "batch_amount = {}\n",
    "for k,d in data.items():\n",
    "  data_loaders[k] = DataLoader(d, batch_size=batch_size, shuffle=(k==\"training\")) \n",
    "  batch_amount[k] = 1 + len(d) // batch_size\n",
    "\n",
    "num_timesteps, num_bands = data[\"training\"][0][0].shape\n",
    "\n",
    "# ------------ Model -----------------------------------------\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerModel(c_in=num_bands, c_out=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# ------------ Optimizer -------------------------------------\n",
    "lr = 0.0001\n",
    "params_to_update = model.parameters()\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vag_syuI_7LC"
   },
   "source": [
    "### 3.3 Training loop\n",
    "Inspired by [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4CEAVqR6Vi4"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "#%%wandb\n",
    "model_name = input(\"Model name: \")\n",
    "num_epochs = 100\n",
    "config={\n",
    "  \"model_name\": model_name,\n",
    "  \"model\": model.__class__,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"num_epochs\": num_epochs,\n",
    "  \"lr\": lr,\n",
    "  \"optimizer\": optimizer.__class__.__name__,\n",
    "  \"loss\": criterion.__class__.__name__,\n",
    "}\n",
    "run = wandb.init(project=PROJECT_ROOT.name, config=config)\n",
    "\n",
    "lowest_validation_loss = None\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), total=num_epochs):  \n",
    "\n",
    "    # ------------------------ Training ----------------------------------------\n",
    "    total_train_loss = 0.0\n",
    "    model.train()\n",
    "    for x in tqdm(data_loaders[\"training\"], total=batch_amount[\"training\"], desc=\"Train\", leave=False):\n",
    "      inputs, labels = x[0].to(device), x[1].to(device)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Get model outputs and calculate loss\n",
    "      outputs = model(inputs.transpose(2,1)).squeeze(dim=1)\n",
    "      outputs = torch.sigmoid(outputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_train_loss += (loss.item() * len(inputs))\n",
    "\n",
    "    # ------------------------ Validation --------------------------------------\n",
    "    total_val_loss = 0.0\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    y_pred = []\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "      for x in tqdm(data_loaders[\"validation\"], total=batch_amount[\"validation\"], desc=\"Validate\", leave=False):\n",
    "        inputs, labels = x[0].to(device), x[1].to(device)\n",
    "\n",
    "        # Get model outputs and calculate loss\n",
    "        outputs = model(inputs.transpose(2,1)).squeeze(dim=1)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_val_loss += (loss.item() * len(inputs))\n",
    "\n",
    "        y_true += labels.tolist()\n",
    "        y_score += outputs.tolist()\n",
    "        y_pred += (outputs > 0.5).long().tolist()\n",
    "    \n",
    "\n",
    "    # ------------------------ Metrics + Logging -------------------------------\n",
    "    train_loss = total_train_loss / len(data[\"training\"])\n",
    "    val_loss = total_val_loss / len(data[\"validation\"])\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ConfusionMatrixDisplay(cm, display_labels=[\"Negative\", \"Positive\"]).plot()\n",
    "    to_log = {\n",
    "      \"train_loss\": train_loss, \n",
    "      \"val_loss\":   val_loss, \n",
    "      \"epoch\":      epoch,\n",
    "      \"accuracy\":   accuracy_score(y_true, y_pred),\n",
    "      \"f1\":         f1_score(y_true, y_pred),\n",
    "      \"precision\":  precision_score(y_true, y_pred),\n",
    "      \"recall\":     recall_score(y_true, y_pred),   \n",
    "      \"roc_auc\":    roc_auc_score(y_true, y_score),\n",
    "      \"confusion_matrix\": wandb.Image(plt)\n",
    "    }\n",
    "    wandb.log(to_log)\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # ------------------------ Model saving --------------------------\n",
    "    if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
    "      lowest_validation_loss = val_loss\n",
    "      sm = torch.jit.script(model)\n",
    "      model_path = FULL_PATHS[\"models\"] / f\"{model_name}.pt\"\n",
    "      if model_path.exists():\n",
    "          model_path.unlink()\n",
    "      sm.save(str(model_path))\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqRGvmJBwOcv"
   },
   "outputs": [],
   "source": [
    "# Newly available models\n",
    "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lm6__TQZoq0"
   },
   "source": [
    "### 3.4 [WIP]: Record test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCWZ7g72Zt21"
   },
   "outputs": [],
   "source": [
    "model_pt = torch.jit.load(str(FULL_PATHS[\"models\"] / f\"{model_name}.pt\"))\n",
    "model_pt.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_score = model_pt(x)[1].numpy()\n",
    "y_pred = y_score > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG94Q3lAzmyu"
   },
   "source": [
    "# 4. Pushing the model to the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fbv1fwFNzrnS"
   },
   "outputs": [],
   "source": [
    "!dvc commit {RELATIVE_PATHS[\"models\"]} -q\n",
    "!dvc push -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EywOpWv8JDV"
   },
   "outputs": [],
   "source": [
    "# Push changes to github\n",
    "!git checkout -b'{model_name}'\n",
    "!git add .\n",
    "!git commit -m 'Trained new: {model_name}'\n",
    "!git push --set-upstream origin \"{model_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YENWoPX_1AJC"
   },
   "source": [
    "Create a Pull Request so the model can be merged into the main branch. When the branch is merged into main."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
