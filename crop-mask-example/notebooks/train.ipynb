{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYSuraxoKJy"
      },
      "source": [
        "# Model training üèã\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasaharvest/openmapflow/blob/main/crop-mask-example/notebooks/train.ipynb)\n",
        "\n",
        "**Description:** Stand alone notebook for training crop-mask models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdI-wLrbxHZn"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "If you don't already have one, obtain a Github Personal Access Token using the steps [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token). Save this token somewhere private."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3otirx9-y6M"
      },
      "outputs": [],
      "source": [
        "email = input(\"Github email: \")\n",
        "username = input(\"Github username: \")\n",
        "\n",
        "!git config --global user.email $username\n",
        "!git config --global user.name $email\n",
        "\n",
        "from getpass import getpass\n",
        "token = getpass('Github Personal Access Token:')\n",
        "\n",
        "# TODO: Generate below two lines from config\n",
        "!git clone https://$username:$token@github.com/nasaharvest/openmapflow.git\n",
        "!cd openmapflow && pip install -r requirements.txt -q\n",
        "%cd openmapflow/crop-mask-example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWoGz94avN0w"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from openmapflow.config import RELATIVE_PATHS, FULL_PATHS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEusgSrCqxaz"
      },
      "source": [
        "# 2. Download latest data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls-7sN9Hoew6"
      },
      "outputs": [],
      "source": [
        "for path_key in tqdm([\"models\", \"processed\", \"compressed_features\"]):\n",
        "    !dvc pull {RELATIVE_PATHS[path_key]} -q\n",
        "\n",
        "!tar -xzf {RELATIVE_PATHS[\"compressed_features\"]} -C data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeANCDe2uJcX"
      },
      "outputs": [],
      "source": [
        "# Currently available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAD4tO5k7nO5"
      },
      "outputs": [],
      "source": [
        "# Available datasets for training and evaluation\n",
        "!cat data/datasets.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gietI36Bykse"
      },
      "source": [
        "# 3. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgSUHMkSyKQ7"
      },
      "outputs": [],
      "source": [
        "# Login to wandb for tracking model runs\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6rJi03Kun9d"
      },
      "outputs": [],
      "source": [
        "model_name = input(\"Model name: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBX3COiquUPN"
      },
      "outputs": [],
      "source": [
        "%%wandb\n",
        "# ------------ Model -----------------------------------------\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ## models.resnet18(pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "# ------------ Optimizer -------------------------------------\n",
        "lr = 0.001\n",
        "params_to_update = model.parameters()\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# ------------ Dataloaders -------------------------------------\n",
        "batch_size = 128\n",
        "train_data = SegmentationData(is_train=True)\n",
        "test_data = SegmentationData(is_train=False)\n",
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_data, batch_size=batch_size, shuffle=True),\n",
        "    \"test\": DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "}\n",
        "batch_amount = {\n",
        "    \"train\": 1 + (len(train_data) // batch_size),\n",
        "    \"test\": 1 + (len(test_data) // batch_size)\n",
        "} \n",
        "\n",
        "#------------ Log config -------------------------------------\n",
        "num_epochs = 10\n",
        "run = wandb.init(project=\"Vision Homework 2\", config={\n",
        "    \"batch_size\": batch_size,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"lr\": lr,\n",
        "    \"optimizer\": \"SGD\"\n",
        "})\n",
        "\n",
        "# ------------ Train -------------------------------------\n",
        "# Inspired by: \n",
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#model-training-and-validation-code\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  # Each epoch has a training and validation phase\n",
        "  for phase in ['train', 'test']:\n",
        "    if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "    else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for x in tqdm(dataloaders[phase], total=batch_amount[phase], desc=phase, leave=False):\n",
        "      inputs = x[\"superpixel image\"]\n",
        "      labels = x[\"superpixel class\"]\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "          # Get model outputs and calculate loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "      # statistics\n",
        "      step_loss = loss.item() * inputs.size(0)\n",
        "      if phase == \"train\":\n",
        "        wandb.log({\"train_loss\": step_loss})\n",
        "\n",
        "      running_loss += step_loss\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "    wandb.log({\n",
        "        f\"{phase}_epoch_loss\": epoch_loss,\n",
        "        f\"{phase}_epoch_acc\": epoch_acc,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "\n",
        "    print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print()\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRGvmJBwOcv"
      },
      "outputs": [],
      "source": [
        "# Newly available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG94Q3lAzmyu"
      },
      "source": [
        "# 4. Pushing the model to the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbv1fwFNzrnS"
      },
      "outputs": [],
      "source": [
        "!dvc pull {RELATIVE_PATHS[\"models\"]}\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EywOpWv8JDV"
      },
      "outputs": [],
      "source": [
        "# Push changes to github\n",
        "!git checkout -b'$model_name'\n",
        "!git add .\n",
        "!git commit -m 'Trained new: $model_name'\n",
        "!git push --set-upstream origin \"$model_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YENWoPX_1AJC"
      },
      "source": [
        "Create a Pull Request so the model can be merged into the main branch. When the branch is merged into main."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}