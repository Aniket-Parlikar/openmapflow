{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYSuraxoKJy"
      },
      "source": [
        "# Model training üèã\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasaharvest/openmapflow/blob/main/crop-mask-example/notebooks/train.ipynb)\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/harvest-public-assets/openmapflow/train_model.png\" width=80%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdI-wLrbxHZn"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "If you don't already have one, obtain a Github Personal Access Token using the steps [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token). Save this token somewhere private."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3otirx9-y6M"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import auth\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    \n",
        "if IN_COLAB:\n",
        "    email = input(\"Github email: \")\n",
        "    username = input(\"Github username: \")\n",
        "\n",
        "    !git config --global user.email $username\n",
        "    !git config --global user.name $email\n",
        "\n",
        "    from getpass import getpass\n",
        "    token = getpass('Github Personal Access Token:')\n",
        "\n",
        "    # TODO: Generate below two lines from config\n",
        "    !git clone https://$username:$token@github.com/nasaharvest/openmapflow.git\n",
        "    !cd openmapflow && pip install -r requirements.txt -q\n",
        "    %cd openmapflow/crop-mask-example\n",
        "else:\n",
        "    print(\"Running notebook outside Google Colab. Assuming in local repository.\")\n",
        "    !cd ../.. && pip install -r requirements.txt -q\n",
        "    !pip install earthengine-api google-auth -q\n",
        "    %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzZn9b3f2ySY"
      },
      "outputs": [],
      "source": [
        "!pip install cmocean torch wandb tsai -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWoGz94avN0w"
      },
      "outputs": [],
      "source": [
        "from cropharvest.bands import DYNAMIC_BANDS\n",
        "from cropharvest.eo import EarthEngineExporter\n",
        "from cropharvest.inference import Inference\n",
        "from cropharvest.countries import BBox\n",
        "from google.cloud import storage\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix, \n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "import cmocean\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio as rio\n",
        "import tempfile\n",
        "import torch\n",
        "import wandb\n",
        "import warnings\n",
        "import yaml\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from openmapflow.config import RELATIVE_PATHS, FULL_PATHS, PROJECT_ROOT\n",
        "from openmapflow.pytorch_dataset import PyTorchDataset\n",
        "from openmapflow.config import SUBSET\n",
        "\n",
        "from datasets import datasets\n",
        "\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning) # TorchScript throws excessive warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEusgSrCqxaz"
      },
      "source": [
        "# 2. Download latest data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls-7sN9Hoew6"
      },
      "outputs": [],
      "source": [
        "for path_key in tqdm([\"models\", \"processed\", \"compressed_features\"]):\n",
        "    !dvc pull {RELATIVE_PATHS[path_key]} -q\n",
        "\n",
        "!tar -xzf {RELATIVE_PATHS[\"compressed_features\"]} -C data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeANCDe2uJcX"
      },
      "outputs": [],
      "source": [
        "# Currently available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAD4tO5k7nO5"
      },
      "outputs": [],
      "source": [
        "# Available datasets for training and evaluation\n",
        "!cat data/datasets.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gietI36Bykse"
      },
      "source": [
        "# 3. Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P13Z7qUQfMJ"
      },
      "source": [
        "### 3.1 Import model\n",
        "Any PyTorch based model that can take sequence data as input will work here.\n",
        "Example uses a PyTorch model from [tsai](https://github.com/timeseriesAI/tsai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEUjElwSELhF"
      },
      "outputs": [],
      "source": [
        "from tsai.models.TransformerModel import TransformerModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAYc2qnpQXu1"
      },
      "source": [
        "### 3.2 Setup training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBX3COiquUPN"
      },
      "outputs": [],
      "source": [
        "# ------------ Dataloaders -------------------------------------\n",
        "batch_size = 64\n",
        "df = datasets[0].load_labels()\n",
        "split_dfs = {\n",
        "    \"training\": df[df[SUBSET] == \"training\"],\n",
        "    \"validation\": df[df[SUBSET] == \"validation\"],\n",
        "    \"testing\": df[df[SUBSET] == \"testing\"]\n",
        "}\n",
        "data = {split: PyTorchDataset(df=df, start_month=\"February\", subset=split) for split, df in split_dfs.items()}\n",
        "data_loaders = {}\n",
        "batch_amount = {}\n",
        "for k,d in data.items():\n",
        "  data_loaders[k] = DataLoader(d, batch_size=batch_size, shuffle=(k==\"training\")) \n",
        "  batch_amount[k] = 1 + len(d) // batch_size\n",
        "\n",
        "num_timesteps, num_bands = data[\"training\"][0][0].shape\n",
        "\n",
        "# ------------ Model -----------------------------------------\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = TransformerModel(c_in=num_bands, c_out=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x.transpose(2,1)).squeeze(dim=1)\n",
        "    x = torch.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model().to(device)\n",
        "\n",
        "# ------------ Optimizer -------------------------------------\n",
        "lr = 0.0001\n",
        "params_to_update = model.parameters()\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vag_syuI_7LC"
      },
      "source": [
        "### 3.3 Training loop\n",
        "Inspired by [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4CEAVqR6Vi4"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "#%%wandb\n",
        "model_name = input(\"Model name: \")\n",
        "num_epochs = 100\n",
        "config={\n",
        "  \"model_name\": model_name,\n",
        "  \"model\": model.__class__,\n",
        "  \"batch_size\": batch_size,\n",
        "  \"num_epochs\": num_epochs,\n",
        "  \"lr\": lr,\n",
        "  \"optimizer\": optimizer.__class__.__name__,\n",
        "  \"loss\": criterion.__class__.__name__,\n",
        "}\n",
        "run = wandb.init(project=PROJECT_ROOT.name, config=config)\n",
        "\n",
        "lowest_validation_loss = None\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), total=num_epochs):  \n",
        "\n",
        "    # ------------------------ Training ----------------------------------------\n",
        "    total_train_loss = 0.0\n",
        "    model.train()\n",
        "    for x in tqdm(data_loaders[\"training\"], total=batch_amount[\"training\"], desc=\"Train\", leave=False):\n",
        "      inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Get model outputs and calculate loss\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_train_loss += (loss.item() * len(inputs))\n",
        "\n",
        "    # ------------------------ Validation --------------------------------------\n",
        "    total_val_loss = 0.0\n",
        "    y_true = []\n",
        "    y_score = []\n",
        "    y_pred = []\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "      for x in tqdm(data_loaders[\"validation\"], total=batch_amount[\"validation\"], desc=\"Validate\", leave=False):\n",
        "        inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "        # Get model outputs and calculate loss\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_val_loss += (loss.item() * len(inputs))\n",
        "\n",
        "        y_true += labels.tolist()\n",
        "        y_score += outputs.tolist()\n",
        "        y_pred += (outputs > 0.5).long().tolist()\n",
        "    \n",
        "\n",
        "    # ------------------------ Metrics + Logging -------------------------------\n",
        "    train_loss = total_train_loss / len(data[\"training\"])\n",
        "    val_loss = total_val_loss / len(data[\"validation\"])\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    ConfusionMatrixDisplay(cm, display_labels=[\"Negative\", \"Positive\"]).plot()\n",
        "    to_log = {\n",
        "      \"train_loss\": train_loss, \n",
        "      \"val_loss\":   val_loss, \n",
        "      \"epoch\":      epoch,\n",
        "      \"accuracy\":   accuracy_score(y_true, y_pred),\n",
        "      \"f1\":         f1_score(y_true, y_pred),\n",
        "      \"precision\":  precision_score(y_true, y_pred),\n",
        "      \"recall\":     recall_score(y_true, y_pred),   \n",
        "      \"roc_auc\":    roc_auc_score(y_true, y_score),\n",
        "      \"confusion_matrix\": wandb.Image(plt)\n",
        "    }\n",
        "    wandb.log(to_log)\n",
        "    plt.close(\"all\")\n",
        "\n",
        "    # ------------------------ Model saving --------------------------\n",
        "    if lowest_validation_loss is None or val_loss < lowest_validation_loss:\n",
        "      lowest_validation_loss = val_loss\n",
        "      sm = torch.jit.script(model)\n",
        "      model_path = FULL_PATHS[\"models\"] / f\"{model_name}.pt\"\n",
        "      if model_path.exists():\n",
        "          model_path.unlink()\n",
        "      sm.save(str(model_path))\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRGvmJBwOcv"
      },
      "outputs": [],
      "source": [
        "# Newly available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lm6__TQZoq0"
      },
      "source": [
        "### 3.4 Record test metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCWZ7g72Zt21"
      },
      "outputs": [],
      "source": [
        "model_pt = torch.jit.load(str(FULL_PATHS[\"models\"] / f\"{model_name}.pt\"))\n",
        "model_pt.eval()\n",
        "\n",
        "y_true = []\n",
        "y_score = []\n",
        "y_pred = []\n",
        "model.eval() \n",
        "with torch.no_grad():\n",
        "  for x in tqdm(data_loaders[\"testing\"], total=batch_amount[\"testing\"], desc=\"Testing\", leave=False):\n",
        "    inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "    # Get model outputs and calculate loss\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    total_val_loss += (loss.item() * len(inputs))\n",
        "\n",
        "    y_true += labels.tolist()\n",
        "    y_score += outputs.tolist()\n",
        "    y_pred += (outputs > 0.5).long().tolist()\n",
        "\n",
        "metrics = {\n",
        "  \"accuracy\":   accuracy_score(y_true, y_pred),\n",
        "  \"f1\":         f1_score(y_true, y_pred),\n",
        "  \"precision\":  precision_score(y_true, y_pred),\n",
        "  \"recall\":     recall_score(y_true, y_pred),   \n",
        "  \"roc_auc\":    roc_auc_score(y_true, y_score),\n",
        "}\n",
        "metrics = {k: round(float(v), 4) for k,v in metrics.items()}\n",
        "\n",
        "all_metrics = {}\n",
        "if FULL_PATHS[\"metrics\"].exists():\n",
        "  with FULL_PATHS[\"metrics\"].open() as f:\n",
        "      all_metrics = yaml.safe_load(f)\n",
        "\n",
        "all_metrics[model_name] = {\"params\": run.url, \"test_metrics\": metrics}\n",
        "\n",
        "with open(FULL_PATHS[\"metrics\"], 'w') as f:\n",
        "    yaml.dump(all_metrics, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG94Q3lAzmyu"
      },
      "source": [
        "# 4. Pushing the model to the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbv1fwFNzrnS"
      },
      "outputs": [],
      "source": [
        "!dvc commit {RELATIVE_PATHS[\"models\"]} -q -f\n",
        "!dvc push -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EywOpWv8JDV"
      },
      "outputs": [],
      "source": [
        "# Push changes to github\n",
        "!git checkout -b'{model_name}'\n",
        "!git add .\n",
        "!git commit -m 'Trained new: {model_name}'\n",
        "!git push --set-upstream origin \"{model_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YENWoPX_1AJC"
      },
      "source": [
        "Create a Pull Request so the model can be merged into the main branch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. [OPTIONAL] Create small map with model"
      ],
      "metadata": {
        "id": "1U7eVuRy9yj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Setup"
      ],
      "metadata": {
        "id": "m2q9N4kwiJT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbox_name = \"Togo_2019_demo\"\n",
        "bbox = BBox(min_lat=6.31, max_lat=6.34, min_lon=1.70, max_lon=1.74)\n",
        "dest_bucket = \"crop-mask-tifs2\"\n",
        "start_date= date(2019, 2, 1)\n",
        "end_date= date(2020,2,1)\n",
        "prefix = f\"{bbox_name}_{start_date}_{end_date}\"\n",
        "print(bbox.url)\n",
        "\n",
        "temp_dir = tempfile.gettempdir()\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "nys8E_hBAEGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Download earth observation data for entire region (bbox)"
      ],
      "metadata": {
        "id": "aFojbqZZiOg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = storage.Client()\n",
        "cloud_tif_list_iterator = client.list_blobs(dest_bucket, prefix=prefix)\n",
        "cloud_tif_list = [\n",
        "    blob.name\n",
        "    for blob in tqdm(cloud_tif_list_iterator, desc=\"Loading tifs already on Google Cloud\")\n",
        "]\n",
        "\n",
        "if len(cloud_tif_list) == 0:\n",
        "  !earthengine authenticate\n",
        "  EarthEngineExporter(check_ee=False, check_gcp=False, dest_bucket=dest_bucket).export_for_bbox(    \n",
        "    bbox=bbox,\n",
        "    bbox_name=bbox_name,\n",
        "    start_date=date(2019, 2, 1),\n",
        "    end_date=date(2020,2,1),\n",
        "    metres_per_polygon=50000,\n",
        "    file_dimensions=256\n",
        "  )\n",
        "  print(\"Earth observation data is being exported, progress: https://code.earthengine.google.com/tasks\")\n",
        "else:\n",
        "  bucket = storage.Client().bucket(dest_bucket)\n",
        "  local_tif_paths = []\n",
        "  for gs_path in tqdm(cloud_tif_list, desc=\"Downloading tifs\"):\n",
        "    local_path = Path(f\"{temp_dir}/{gs_path.replace('/', '_')}\")\n",
        "    if not local_path.exists():\n",
        "      bucket.blob(gs_path).download_to_filename(local_path)\n",
        "    local_tif_paths.append(local_path)"
      ],
      "metadata": {
        "id": "BCjiMASKIsWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Make predictions for each pixel in the earth observation data\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/harvest-public-assets/openmapflow/basic_inference.png\" width=\"80%\"/>"
      ],
      "metadata": {
        "id": "uRFRu-q_iY2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference = Inference(model=model, normalizing_dict=None, device=device, batch_size=batch_size)\n",
        "local_pred_paths = []\n",
        "for local_tif_path in tqdm(local_tif_paths, desc=\"Making predictions\"):\n",
        "  local_pred_path = Path(f\"{temp_dir}/pred_{local_tif_path.stem}.nc\")\n",
        "  inference.run(\n",
        "      local_path=local_tif_path, \n",
        "      start_date=start_date, \n",
        "      dest_path=local_pred_path\n",
        "  )\n",
        "  local_pred_paths.append(local_pred_path)"
      ],
      "metadata": {
        "id": "Jy5S0UJmMiDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Merge pixel predictions into single map\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/harvest-public-assets/openmapflow/merging_predictions.png\" width=\"60%\"/>"
      ],
      "metadata": {
        "id": "1FdMBEvTimEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_tifs(full_prefix):\n",
        "  vrt_in_file = f\"{full_prefix}*\"\n",
        "  vrt_out_file = f\"{full_prefix}.vrt\"\n",
        "  merged_file = f\"{full_prefix}.tif\"\n",
        "  !gdalbuildvrt {vrt_out_file} {vrt_in_file}\n",
        "  !gdal_translate -a_srs EPSG:4326 -of GTiff {vrt_out_file} {merged_file}\n",
        "  return merged_file\n",
        "\n",
        "merged_eo_file = merge_tifs(full_prefix=f\"{temp_dir}/{prefix}\")\n",
        "merged_pred_file = merge_tifs(full_prefix=f\"{temp_dir}/pred_{prefix}\")"
      ],
      "metadata": {
        "id": "DVjXSffaN02f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5 Visualize earth observation data and predictions map"
      ],
      "metadata": {
        "id": "ZJhp96V4iu_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(array):\n",
        "    array_min, array_max = array.min(), array.max()*0.6\n",
        "    return ((array - array_min)/(array_max - array_min))\n",
        "\n",
        "month = 2\n",
        "rgb_indexes = [DYNAMIC_BANDS.index(b) for b in [\"B4\", \"B3\", \"B2\"]]\n",
        "colors = [eo_map.read(i + month*len(DYNAMIC_BANDS)) for i in rgb_indexes]\n",
        "normalized_colors = [normalize(c) for c in colors]\n",
        "rgb = np.dstack(normalized_colors)\n",
        "plt.title(\"Earth Observation data for one month\")\n",
        "plt.axis('off')\n",
        "plt.imshow(rgb);"
      ],
      "metadata": {
        "id": "rBLKrprQZSb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_map = rio.open(merged_pred_file)\n",
        "plt.title(\"Model predicted map\")\n",
        "plt.axis('off')\n",
        "rio.plot.show(predictions_map, cmap=cmocean.cm.speed);"
      ],
      "metadata": {
        "id": "IhoY-ujuVQYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "15HvW7YWgJ0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}