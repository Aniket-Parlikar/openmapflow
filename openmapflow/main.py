from collections import namedtuple
from typing import List, Optional

import subprocess
import tarfile

from .config import project_root, relative_paths, full_paths
from .all_features import AllFeatures
from .dataset import LabeledDataset


def _dvc(command: str, dvc_dir_name: Optional[str] = None):
    if command not in ["pull", "commit", "push"]:
        raise ValueError(f"Unknown command: {command}")

    if dvc_dir_name is None:
        return subprocess.run(["dvc", "command"], check=True)

    dvc_dir = project_root / f"data/{dvc_dir_name}"
    if not dvc_dir.exists():
        subprocess.run(["dvc", "pull", f"data/{dvc_dir_name}"], check=True)
        if not dvc_dir.exists():
            raise FileExistsError(f"{str(dvc_dir)} was not found.")
        if not any(dvc_dir.iterdir()):
            raise FileExistsError(f"{str(dvc_dir)} should not be empty.")


def dvc_pull(dvc_dir_name: str):
    _dvc("pull", dvc_dir_name)


def dvc_commit(dvc_dir_name: str):
    _dvc("commit", dvc_dir_name)


def dvc_push():
    _dvc("push")


def get_training_data():
    dvc_pull(relative_paths["raw"])
    dvc_pull(relative_paths["processed"])
    dvc_pull(relative_paths["compressed_features.tar.gz"])
    tar = tarfile.open(relative_paths["compressed_features.tar.gz"], "r:gz")
    tar.extractall()
    tar.close()


def push_new_training_data():
    dvc_commit(relative_paths["raw"])
    dvc_commit(relative_paths["processed"])
    dvc_commit(relative_paths["compressed_features.tar.gz"])
    dvc_push()


def create_features(datasets: List[LabeledDataset]):
    get_training_data()

    report = "DATASET REPORT (autogenerated, do not edit directly)"
    for d in datasets:
        text = d.create_features()
        report += "\n\n" + text

    all_features = AllFeatures()
    empty_text = all_features.check_empty()
    print(empty_text)
    duplicates_text = all_features.check_duplicates()
    print(duplicates_text)
    report += "\n\nAll data:\n" + empty_text + "\n" + duplicates_text

    with full_paths["datasets"].open("w") as f:
        f.write(report)

    # Compress features for faster CI/CD
    print("Compressing features...")
    with tarfile.open(full_paths["datasets"], "w:gz") as tar:
        tar.add(full_paths["datasets"], arcname="features")
